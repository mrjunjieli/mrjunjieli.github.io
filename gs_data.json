{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "CInvjq8AAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Junjie Li", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=CInvjq8AAAAJ&citpid=9", "affiliation": "Ph.D., The Hong Kong Polytechnic University; Graduate Student, Tianjin University", "organization": 10969585421171712084, "interests": ["Speech separation", "Speaker recognition"], "email_domain": "@connect.polyu.hk", "homepage": "https://mrjunjieli.github.io/", "citedby": 105, "publications": {"CInvjq8AAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Information bottleneck theory on convolutional neural networks", "pub_year": "2021"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:u5HHmVD_uO8C", "num_citations": 24, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10546840897788327271", "cites_id": ["10546840897788327271"]}, "CInvjq8AAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Wesep: A scalable and flexible toolkit towards generalizable target speaker extraction", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:ufrVoPGSRksC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=368250248540181585", "cites_id": ["368250248540181585"]}, "CInvjq8AAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rethinking the visual cues in audio-visual speaker extraction", "pub_year": "2023"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:IjCSPb-OGe4C", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6799549043130777084", "cites_id": ["6799549043130777084"]}, "CInvjq8AAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VCSE: Time-domain visual-contextual speaker extraction network", "pub_year": "2022"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:LkGwnXOMwfcC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17701452057468009531", "cites_id": ["17701452057468009531"]}, "CInvjq8AAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-level speaker representation for target speaker extraction", "pub_year": "2025"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:_FxGoFyzp5QC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4095309933858024913", "cites_id": ["4095309933858024913"]}, "CInvjq8AAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audio-visual active speaker extraction for sparsely overlapped multi-talker speech", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:zYLM7Y9cAGgC", "num_citations": 7, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11422752646877001455", "cites_id": ["11422752646877001455"]}, "CInvjq8AAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "On the effectiveness of enrollment speech augmentation for target speaker extraction", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:YsMSGLbcyi4C", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8933712048313067002", "cites_id": ["8933712048313067002"]}, "CInvjq8AAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deep multi-task cascaded acoustic echo cancellation and noise suppression", "pub_year": "2022"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:9yKSN-GCB0IC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15933752176920655872", "cites_id": ["15933752176920655872"]}, "CInvjq8AAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Stream attention based U-Net for L3DAS23 challenge", "pub_year": "2023"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:qjMakFHDy7sC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18379442636566075367", "cites_id": ["18379442636566075367"]}, "CInvjq8AAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audio-visual target speaker extraction with selective auditory attention", "pub_year": "2025"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:hqOjcs7Dif8C", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9227593720606280442", "cites_id": ["9227593720606280442"]}, "CInvjq8AAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audio-visual target speaker extraction with reverse selective auditory attention", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:W7OEmFMy1HYC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12075001526302083776", "cites_id": ["12075001526302083776"]}, "CInvjq8AAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MoMuSE: Momentum Multi-modal Target Speaker Extraction for Real-time Scenarios with Impaired Visual Cues", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:Se3iqnhoufwC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10871031477860969235", "cites_id": ["10871031477860969235"]}, "CInvjq8AAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing Speaker Extraction Through Rectifying Target Confusion", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:UebtZRa9Y70C", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8347799377657096123", "cites_id": ["8347799377657096123"]}, "CInvjq8AAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Listen to the Speaker in Your Gaze", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:eQOLeE2rZwMC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9085151408126986915", "cites_id": ["9085151408126986915"]}, "CInvjq8AAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MeMo: Attentional Momentum for Real-time Audio-visual Speaker Extraction under Impaired Visual Conditions", "pub_year": "2025"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:0EnyYjriUFMC", "num_citations": 0}}, "citedby5y": 105, "hindex": 6, "hindex5y": 6, "i10index": 4, "i10index5y": 4, "cites_per_year": {"2020": 1, "2021": 4, "2022": 5, "2023": 15, "2024": 34, "2025": 45}, "updated": "2025-09-06 08:11:21.007352"}