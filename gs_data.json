{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "CInvjq8AAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Junjie Li", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=CInvjq8AAAAJ&citpid=9", "affiliation": "Ph.D., The Hong Kong Polytechnic University; Graduate Student, Tianjin University", "organization": 10969585421171712084, "interests": ["Speech separation", "Multi-modal", "Speaker recognition", "Voice security and privacy"], "email_domain": "@connect.polyu.hk", "homepage": "https://mrjunjieli.github.io/", "citedby": 131, "publications": {"CInvjq8AAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Information bottleneck theory on convolutional neural networks", "pub_year": "2021"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:u5HHmVD_uO8C", "num_citations": 25, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10546840897788327271", "cites_id": ["10546840897788327271"]}, "CInvjq8AAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Wesep: A scalable and flexible toolkit towards generalizable target speaker extraction", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:ufrVoPGSRksC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=368250248540181585", "cites_id": ["368250248540181585"]}, "CInvjq8AAAAJ:IjCSPb-OGe4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rethinking the visual cues in audio-visual speaker extraction", "pub_year": "2023"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:IjCSPb-OGe4C", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6799549043130777084", "cites_id": ["6799549043130777084"]}, "CInvjq8AAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-level speaker representation for target speaker extraction", "pub_year": "2025"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:_FxGoFyzp5QC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4095309933858024913", "cites_id": ["4095309933858024913"]}, "CInvjq8AAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VCSE: Time-domain visual-contextual speaker extraction network", "pub_year": "2022"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:LkGwnXOMwfcC", "num_citations": 12, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17701452057468009531", "cites_id": ["17701452057468009531"]}, "CInvjq8AAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "On the effectiveness of enrollment speech augmentation for target speaker extraction", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:YsMSGLbcyi4C", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8933712048313067002", "cites_id": ["8933712048313067002"]}, "CInvjq8AAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audio-visual active speaker extraction for sparsely overlapped multi-talker speech", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:zYLM7Y9cAGgC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11422752646877001455", "cites_id": ["11422752646877001455"]}, "CInvjq8AAAAJ:hqOjcs7Dif8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audio-visual target speaker extraction with selective auditory attention", "pub_year": "2025"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:hqOjcs7Dif8C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9227593720606280442", "cites_id": ["9227593720606280442"]}, "CInvjq8AAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Deep multi-task cascaded acoustic echo cancellation and noise suppression", "pub_year": "2022"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:9yKSN-GCB0IC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15933752176920655872", "cites_id": ["15933752176920655872"]}, "CInvjq8AAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audio-visual target speaker extraction with reverse selective auditory attention", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:W7OEmFMy1HYC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12075001526302083776", "cites_id": ["12075001526302083776"]}, "CInvjq8AAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Stream attention based U-Net for L3DAS23 challenge", "pub_year": "2023"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:qjMakFHDy7sC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18379442636566075367", "cites_id": ["18379442636566075367"]}, "CInvjq8AAAAJ:Se3iqnhoufwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Momuse: Momentum multi-modal target speaker extraction for real-time scenarios with impaired visual cues", "pub_year": "2025"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:Se3iqnhoufwC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10871031477860969235", "cites_id": ["10871031477860969235"]}, "CInvjq8AAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing Speaker Extraction Through Rectifying Target Confusion", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:UebtZRa9Y70C", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8347799377657096123", "cites_id": ["8347799377657096123"]}, "CInvjq8AAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Xi+: Uncertainty Supervision for Robust Speaker Embedding", "pub_year": "2025"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:8k81kl-MbHgC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7546429852306100257", "cites_id": ["7546429852306100257"]}, "CInvjq8AAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MeMo: Attentional Momentum for Real-time Audio-visual Speaker Extraction under Impaired Visual Conditions", "pub_year": "2025"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:0EnyYjriUFMC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17782469812563565860", "cites_id": ["17782469812563565860"]}, "CInvjq8AAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Listen to the Speaker in Your Gaze", "pub_year": "2024"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:eQOLeE2rZwMC", "num_citations": 1, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9085151408126986915", "cites_id": ["9085151408126986915"]}, "CInvjq8AAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "U3-xi: Pushing the Boundaries of Speaker Recognition via Incorporating Uncertainty", "pub_year": "2026"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:kNdYIx-mwKoC", "num_citations": 0}, "CInvjq8AAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "QAMO: Quality-aware Multi-centroid One-class Learning For Speech Deepfake Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:3fE2CSJIrl8C", "num_citations": 0}, "CInvjq8AAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Addressing Gradient Misalignment in Data-Augmented Training for Robust Speech Deepfake Detection", "pub_year": "2025"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:MXK_kJrjxJIC", "num_citations": 0}, "CInvjq8AAAAJ:5nxA0vEk-isC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Do We Really Need GNNs with Explicit Structural Modeling? MLPs Suffice for Language Model Representations", "pub_year": "2025"}, "filled": false, "author_pub_id": "CInvjq8AAAAJ:5nxA0vEk-isC", "num_citations": 0}}, "citedby5y": 130, "hindex": 8, "hindex5y": 8, "i10index": 6, "i10index5y": 6, "cites_per_year": {"2020": 1, "2021": 3, "2022": 5, "2023": 15, "2024": 32, "2025": 68, "2026": 7}, "updated": "2026-01-28 08:17:50.764617"}